{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Autoencoder"],"metadata":{"id":"F8xvaZAqZaLJ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPKNjsk8efiH","outputId":"325da437-64c5-44b8-9d8c-6f83a39f92e6","executionInfo":{"status":"ok","timestamp":1669225483332,"user_tz":180,"elapsed":20740,"user":{"displayName":"Hélio Bomfim de Macêdo Filho","userId":"12339815194939898124"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["params.py"],"metadata":{"id":"WSVgjnBrcibn"}},{"cell_type":"code","source":["LOCAL_REGISTRY_PATH='/content/gdrive/MyDrive/Bootcamp_ENAP_2022/new_output/model'\n","LOCAL_DATA_PATH_OUTPUT_IMG='/content/gdrive/MyDrive/Bootcamp_ENAP_2022/new_output/processed_img'\n","\n","AUTOENCODER_WIDTH=160\n","AUTOENCODER_HEIGHT=192\n","AUTOENCODER_LEARNING_RATE=0.0005\n","AUTOENCODER_LOSS_FACTOR=10000\n","AUTOENCODER_PATIENCE=20\n","AUTOENCODER_VALIDATION_SPLIT=0.3\n","AUTOENCODER_BATCHSIZE=256\n","AUTOENCODER_LATENT_DIMENSION=500\n","AUTOENCODER_N_EPOCHS=400\n","DATA_SOURCE='local'\n","CHUNK_SIZE=10000"],"metadata":{"id":"_xO_j6qcch2G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["registry.py"],"metadata":{"id":"AWJaZKlAb0kS"}},{"cell_type":"code","source":["import time\n","import glob\n","import pickle\n","import os\n","from tensorflow.keras import Model, models\n","\n","def load_autoencoder(elected: bool, bw: bool, custom_objects: dict, save_copy_locally=False) -> Model:\n","    \"\"\"\n","    load the latest saved autoencoder, return None if no autoencoder found\n","    \"\"\"\n","\n","    print(\"\\nLoad autoencoder from local disk...\")\n","\n","   # get latest model version\n","    autoencoder_directory = os.path.join(LOCAL_REGISTRY_PATH,\n","        'bw' if bw else 'color',\n","        'elected' if elected else 'not_elected',\n","        'models', 'autoencoder')\n","\n","    results = glob.glob(f\"{autoencoder_directory}/*\")\n","    if not results:\n","        return None\n","\n","    autoencoder_path = sorted(results)[-1]\n","    print(f\"- path: {autoencoder_path}\")\n","\n","    autoencoder = models.load_model(autoencoder_path, custom_objects=custom_objects)\n","    print(\"\\n✅ autoencoder loaded from disk\")\n","\n","    return autoencoder\n","\n","def save_autoencoder(autoencoder: Model = None,\n","               params: dict = None,\n","               metrics: dict = None,\n","               elected: bool = None,\n","               bw: bool = None) -> None:\n","\n","    \"\"\"\n","    persist trained autoencoder, params and metrics\n","    \"\"\"\n","\n","    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n","\n","    print(\"\\nSave autoencoder to local disk...\")\n","\n","    # save params\n","    if params is not None:\n","        params_path = os.path.join(LOCAL_REGISTRY_PATH,\n","        'bw' if bw else 'color',\n","        'elected' if elected else 'not_elected',\n","        'params', 'autoencoder')\n","\n","        if not os.path.exists(params_path):\n","            os.makedirs(params_path)\n","\n","        print(f\"- params path: {params_path}\")\n","        with open(os.path.join(params_path,timestamp + \".pickle\"), \"wb\") as file:\n","            pickle.dump(params, file)\n","\n","    # save metrics\n","    if metrics is not None:\n","        metrics_path = os.path.join(LOCAL_REGISTRY_PATH,\n","        'bw' if bw else 'color',\n","        'elected' if elected else 'not_elected',\n","        'metrics', 'autoencoder')\n","\n","        if not os.path.exists(metrics_path):\n","            os.makedirs(metrics_path)\n","\n","        print(f\"- metrics path: {metrics_path}\")\n","        with open(os.path.join(metrics_path,timestamp + \".pickle\"), \"wb\") as file:\n","            pickle.dump(metrics, file)\n","\n","    # save autoencoder\n","    if autoencoder is not None:\n","        autoencoder_path = os.path.join(LOCAL_REGISTRY_PATH,\n","        'bw' if bw else 'color',\n","        'elected' if elected else 'not_elected',\n","        'models', 'autoencoder')\n","\n","        if not os.path.exists(autoencoder_path):\n","            os.makedirs(autoencoder_path)\n","\n","        print(f\"- autoencoder path: {autoencoder_path}\")\n","        autoencoder.save(os.path.join(autoencoder_path, timestamp + \".model\"))\n","\n","    print(\"\\n✅ data saved locally\")\n","\n","    return None\n"],"metadata":{"id":"sUjM6RA5ZP-9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model.py"],"metadata":{"id":"KfCCPnS2c89z"}},{"cell_type":"code","source":["from typing import Tuple\n","import numpy as np\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Masking\n","from tensorflow.keras import Model, backend as K\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","def r_loss(y_true, y_pred):\n","    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n","\n","def kl_loss(y_true, y_pred):\n","    kl_loss =  -0.5 * K.sum(1 + log_var - K.square(mean_mu) - K.exp(log_var), axis = 1)\n","    return kl_loss\n","\n","def total_loss(y_true, y_pred):\n","    return AUTOENCODER_LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n","\n","def build_prefix_encoder(input_shape, use_batch_norm = False, use_dropout = False):\n","    global K\n","    K.clear_session()\n","\n","    '''returns an encoder model, of output_shape equals to latent_dimension'''\n","    encoder = Sequential()\n","\n","    encoder.add(Masking(mask_value=255, input_shape=input_shape))\n","    encoder.add(Rescaling(1./255))\n","\n","    encoder.add(Conv2D(32, (3,3), (2, 2), padding='same', activation='LeakyReLU'))\n","    if use_batch_norm: encoder.add(BatchNormalization())\n","    if use_dropout: encoder.add(Dropout(0.25))\n","\n","    encoder.add(Conv2D(64, (3,3), (2, 2), padding='same', activation='LeakyReLU'))\n","    if use_batch_norm: encoder.add(BatchNormalization())\n","    if use_dropout: encoder.add(Dropout(0.25))\n","\n","    encoder.add(Conv2D(64, (3,3), (2, 2), padding='same', activation='LeakyReLU'))\n","    if use_batch_norm: encoder.add(BatchNormalization())\n","    if use_dropout: encoder.add(Dropout(0.25))\n","\n","    encoder.add(Conv2D(64, (3,3), (2, 2), padding='same', activation='LeakyReLU'))\n","    if use_batch_norm: encoder.add(BatchNormalization())\n","    if use_dropout: encoder.add(Dropout(0.25))\n","\n","    shape_before_flattening = K.int_shape(encoder.layers[-1].output)[1:]\n","\n","    encoder.add(Flatten())\n","\n","    return encoder, shape_before_flattening\n","\n","def build_suffix_encoder(prefix_model, latent_dimension):\n","  prefix_model_input = prefix_model.layers[0].input\n","  prefix_model_output = prefix_model.layers[-1].output\n","\n","  mean_mu = Dense(latent_dimension)(prefix_model_output)\n","  log_var = Dense(latent_dimension)(prefix_model_output)\n","\n","  # Defining a function for sampling\n","  def sampling(args):\n","    global mean_mu\n","    global log_var\n","    mean_mu, log_var = args\n","    epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0., stddev=1.)\n","    return mean_mu + K.exp(log_var/2)*epsilon\n","\n","  concatenate = Lambda(sampling)([mean_mu, log_var])\n","  return Model(prefix_model_input, concatenate)\n","\n","def build_encoder(input_shape, use_batch_norm = False, use_dropout = False, latent_dimension=200):\n","  prefix_encoder, shape_before_flattening = build_prefix_encoder(input_shape, use_batch_norm, use_dropout)\n","  encoder = build_suffix_encoder(prefix_encoder, latent_dimension)\n","  return encoder, shape_before_flattening\n","\n","def build_decoder(latent_dimension, shape_before_flattening):\n","  decoder = Sequential()\n","  decoder.add(Dense(np.prod(shape_before_flattening), input_shape=(latent_dimension, ), activation=None))\n","  decoder.add(Reshape(shape_before_flattening))\n","  decoder.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2,2), padding='same', activation='LeakyReLU'))\n","  decoder.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2,2), padding='same', activation='LeakyReLU'))\n","  decoder.add(Conv2DTranspose(32, kernel_size=(3,3), strides=(2,2), padding='same', activation='LeakyReLU'))\n","  decoder.add(Conv2DTranspose(3, kernel_size=(3,3), strides=(2,2), padding='same', activation='sigmoid'))\n","  return decoder\n","\n","def build_autoencoder(input_shape, latent_dimension):\n","  encoder, shape_before_flattening = build_encoder(input_shape, True, True, latent_dimension)\n","  decoder = build_decoder(latent_dimension, shape_before_flattening)\n","  autoencoder = Model(encoder.layers[0].input, decoder(encoder.layers[-1].output))\n","  return autoencoder, encoder, decoder\n","\n","def initialize_autoencoder(X: np.ndarray, latent_dimension: int) -> Model:\n","    \"\"\"\n","    Initialize the Neural Network with random weights\n","    \"\"\"\n","    autoencoder, _, _ = build_autoencoder(X.shape[1:], latent_dimension)\n","    print(\"\\n✅ autoencoder initialized\")\n","\n","    return autoencoder\n","\n","def compile_autoencoder(autoencoder: Model) -> Model:\n","    \"\"\"\n","    Compile the Neural Network\n","    \"\"\"\n","\n","    adam_optimizer = Adam(learning_rate = AUTOENCODER_LEARNING_RATE)\n","\n","    autoencoder.compile(optimizer=adam_optimizer, loss = total_loss, metrics = [r_loss, kl_loss])\n","\n","    print(\"\\n✅ autoencoder compiled\")\n","    return autoencoder\n","\n","def train_autoencoder(autoencoder: Model,\n","                X: np.ndarray,\n","                y: np.ndarray) -> Tuple[Model, dict]:\n","    \"\"\"\n","    Fit autoencoder and return a the tuple (fitted_autoencoder, history)\n","    \"\"\"\n","\n","    print(\"\\nTrain autoencoder...\")\n","\n","    es = EarlyStopping(patience=AUTOENCODER_PATIENCE, restore_best_weights=True, monitor='val_kl_loss')\n","\n","    history = autoencoder.fit(X,\n","                        y,\n","                        validation_split=AUTOENCODER_VALIDATION_SPLIT,\n","                        epochs=AUTOENCODER_N_EPOCHS,\n","                        batch_size=AUTOENCODER_BATCHSIZE,\n","                        callbacks=[es],\n","                        verbose=1,\n","                        shuffle=True)\n","\n","    print(f\"\\n✅ autoencoder trained ({len(X)} rows)\")\n","\n","    return autoencoder, history\n","\n","def evaluate_autoencoder(autoencoder: Model,\n","                   X: np.ndarray,\n","                   y: np.ndarray) -> Tuple[Model, dict]:\n","    \"\"\"\n","    Evaluate trained autoencoder performance on dataset\n","    \"\"\"\n","\n","    print(f\"\\nEvaluate autoencoder on {len(X)} rows...\")\n","\n","    if autoencoder is None:\n","        print(f\"\\n❌ no autoencoder to evaluate\")\n","        return None\n","\n","    metrics = autoencoder.evaluate(\n","        x=X,\n","        y=y,\n","        batch_size=AUTOENCODER_BATCHSIZE,\n","        verbose=1,\n","        # callbacks=None,\n","        return_dict=True)\n","\n","    r_loss = metrics[\"r_loss\"]\n","    kl_loss = metrics[\"kl_loss\"]\n","\n","    print(f\"\\n✅ autoencoder evaluated: loss {round(r_loss, 2)} mae {round(kl_loss, 2)}\")\n","\n","    return metrics\n"],"metadata":{"id":"LOCmoThlZqMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["main.py"],"metadata":{"id":"x9BY4u8pdMjM"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","from tensorflow.keras.utils import image_dataset_from_directory\n","from tensorflow.keras import Model\n","from tensorflow.errors import NotFoundError\n","\n","def train():\n","    partial_train_autoencoder(True, False)\n","    partial_train_autoencoder(False, False)\n","    partial_train_autoencoder(True, True)\n","    partial_train_autoencoder(False, True)\n","\n","def partial_train_autoencoder(elected=True, bw=True):\n","    \"\"\"\n","    Train a new model on the full (already preprocessed) dataset ITERATIVELY, by loading it\n","    chunk-by-chunk, and updating the weight of the model after each chunks.\n","    Save final model once it has seen all data, and compute validation metrics on a holdout validation set\n","    common to all chunks.\n","    \"\"\"\n","    print(\"\\n⭐️ use case: fit autoencoder\")\n","\n","    print(\"\\nLoading preprocessed data...\")\n","\n","    folder = os.path.join(\n","        LOCAL_DATA_PATH_OUTPUT_IMG,\n","        'elected' if elected else 'not_elected',\n","        'bw' if bw else 'color')\n","\n","    normalized_images_dataset = None\n","    # load a train set\n","    try:\n","        images_dataset = image_dataset_from_directory(folder,\n","                                                      label_mode=None,\n","                                                      batch_size=CHUNK_SIZE,\n","                                                      image_size=(AUTOENCODER_HEIGHT,AUTOENCODER_WIDTH),\n","                                                      shuffle=True,\n","                                                      crop_to_aspect_ratio=True)\n","    except NotFoundError:\n","        print(\"\\n✅ no data to train\")\n","        return None\n","\n","    autoencoder = None\n","    #autoencoder = load_autoencoder(elected, bw, {'r_loss': r_loss, 'kl_loss': kl_loss, 'total_loss': total_loss})  # production model\n","\n","    # iterate on the full dataset per chunks\n","    chunk_id = 0\n","    row_count = 0\n","    metrics_r_loss_list = []\n","    metrics_kl_loss_list = []\n","\n","    for image_batch in images_dataset:\n","\n","        print(f\"\\n✅ Loading and training on preprocessed chunk n°{chunk_id}...\")\n","\n","        # increment trained row count\n","        chunk_row_count = image_batch.shape[0]\n","        row_count += chunk_row_count\n","\n","        # initialize autoencoder\n","        if autoencoder is None:\n","            autoencoder = initialize_autoencoder(image_batch, AUTOENCODER_LATENT_DIMENSION)\n","\n","        # (re)compile and train the model incrementally\n","        autoencoder = compile_autoencoder(autoencoder)\n","        autoencoder, history = train_autoencoder(autoencoder,\n","                                     image_batch,\n","                                     image_batch/255)\n","\n","        metrics_r_loss = np.min(history.history['r_loss'])\n","        metrics_kl_loss = np.min(history.history['kl_loss'])\n","        metrics_r_loss_list.append(metrics_r_loss)\n","        metrics_kl_loss_list.append(metrics_kl_loss)\n","        print(f\"chunk r_loss, kl_loss: {round(metrics_r_loss,2)}, {round(metrics_kl_loss,2)}\")\n","\n","        chunk_id += 1\n","\n","    if row_count == 0:\n","        print(\"\\n✅ no new data for the training 👌\")\n","        return\n","\n","    # return the last value of the validation MAE\n","    val_r_loss, val_kl_loss = metrics_r_loss_list[-1], metrics_kl_loss_list[-1]\n","\n","    print(f\"\\n✅ trained on {row_count} rows with r_loss, kl_loss: {round(val_r_loss, 2)}, {round(val_kl_loss, 2)}\")\n","\n","    params = dict(\n","        # model parameters\n","        learning_rate=AUTOENCODER_LEARNING_RATE,\n","        batch_size=AUTOENCODER_BATCHSIZE,\n","        patience=AUTOENCODER_PATIENCE,\n","        # package behavior\n","        context=\"train\",\n","        chunk_size=CHUNK_SIZE,\n","        # data source\n","        training_set_size=round(row_count*(1-AUTOENCODER_VALIDATION_SPLIT)),\n","        val_set_size=round(row_count*AUTOENCODER_VALIDATION_SPLIT),\n","        row_count=row_count,\n","        model_version=None,\n","        dataset_timestamp=time.strftime(\"%Y%m%d-%H%M%S\"),\n","    )\n","\n","    # save autoencoder\n","    save_autoencoder(autoencoder=autoencoder, params=params, metrics=dict(r_loss= val_r_loss, kl_loss=val_kl_loss), elected=elected, bw=bw)\n","\n","    return val_r_loss, val_kl_loss\n","\n","def pred(autoencoder: Model, X_pred: np.ndarray = None) -> np.ndarray:\n","    \"\"\"\n","    Make a prediction using the latest trained model\n","    \"\"\"\n","\n","    print(\"\\n⭐️ use case: predict\")\n","\n","    if X_pred is None:\n","        decoder = Model(autoencoder.layers[-1].input, autoencoder.layers[-1].output)\n","        y_pred = decoder.predict(np.random.normal(0,1,size=(1,autoencoder.layers[-2].output.shape[1])))\n","        return y_pred\n","\n","    y_pred = autoencoder.predict(X_pred)\n","\n","    print(\"\\n✅ prediction done: \", y_pred.shape)\n","\n","    return y_pred"],"metadata":{"id":"3_IOxWuyZqJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#partial_train_autoencoder(elected=True, bw=False)\n","train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"58-HXxymdXCP","outputId":"54fc7578-76da-4d5b-b03a-febed9ec7891","executionInfo":{"status":"error","timestamp":1669211080928,"user_tz":180,"elapsed":8,"user":{"displayName":"Marcela Correa","userId":"18268533629094762181"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-67b217ddcda9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpartial_train_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-13c6ced9118e>\u001b[0m in \u001b[0;36mpartial_train_autoencoder\u001b[0;34m(elected, bw)\u001b[0m\n\u001b[1;32m     65\u001b[0m         autoencoder, history = train_autoencoder(autoencoder,\n\u001b[1;32m     66\u001b[0m                                      \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                      image_batch/255)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmetrics_r_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-768067b7d05d>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(autoencoder, X, y)\u001b[0m\n\u001b[1;32m    128\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                         shuffle=True)\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n✅ autoencoder trained ({len(X)} rows)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"fpOeVOBalP8T"},"execution_count":null,"outputs":[]}]}